---
title: 'Pyramid Vision Transformer (PVT) and sequences reduction in PVT'
date: 2024-01-13
permalink: /posts/2023/01/pvt/
tags:
  - pvt
  - segformer
  - dat++
  - agent-attention
---

Review
======
The Pyramid Vision Transformer (PVT) tries to combine advatanges of convolutional neural networks (CNNs) with their progressive shrinking pyrmid to reduce 
computations of the large feature maps and and Vision Transformer's (ViT) self-attentions at different resolution outputs. The same basic idea is 
applied in SegFormer model but without explicit position embedding instead they applied padding with overlapping patches, the padding area should help
model to obtain its relative and absolute position (additional: also masking **[MASK]** in decoder can be used instead of positional embedding, the model
is able to learn positional information using only masks). Also they use sequences reduction in order to decrease computational cost. From this the next paper
using the same idea as a sequences reduction but instead of feature size reduction they using learnable parameters with reduced feature size, as result it shows better
results compared the previous methods.

## References
1. [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/pdf/2102.12122.pdf)
2. [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/pdf/2105.15203.pdf)
3. [PVT-SSD: Single-Stage 3D Object Detector with Point-Voxel Transformer](https://arxiv.org/pdf/2305.06621v1.pdf)
4. [Agent Attention: On the Integration of Softmax and Linear Attention](https://arxiv.org/pdf/2312.08874.pdf)
5. [DAT++: Spatially Dynamic Vision Transformer with Deformable Attention](https://arxiv.org/pdf/2309.01430v1.pdf)

------
